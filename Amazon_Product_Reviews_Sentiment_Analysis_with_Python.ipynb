{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Wab3jjr7grVRGmOuA7yJ_xQhSR5szREC",
      "authorship_tag": "ABX9TyO1E6cNDo04OeK/3ej9ZG/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chidroop23/Amazon-Product-Reviews-Sentiment-Analysis-with-Python-/blob/main/Amazon_Product_Reviews_Sentiment_Analysis_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hJuAJ-Qx7Je4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let’s start this task of Amazon review sentiment analysis by importing the necessary Python libraries and the dataset:\n",
        "def load_the_dataset():\n",
        "    data =  pd.read_csv('Reviews.csv')\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "IVRQia8j8LTA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2\n",
        "# As this dataset is very large, it contains some missing values, so let’s remove all the rows containing the missing values:\n",
        "def pre_processing():\n",
        "    data = load_the_dataset()\n",
        "    data = data.dropna()\n",
        "    return data"
      ],
      "metadata": {
        "id": "j8qi76jw8ZJ_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3\n",
        "# The Score column of this dataset contains the ratings that customers have given to the product based on their experience with the product.\n",
        "# So let’s take a look at the rating breakdown to see how most customers rate the products they buy from Amazon:\n",
        "def distribution_of_ratings():\n",
        "    data = pre_processing()\n",
        "\n",
        "    # Calculate the count of unique values in the \"Score\" column\n",
        "    score_counts = data['Score'].value_counts()\n",
        "\n",
        "    # Extract index and values of the counts\n",
        "    score_labels = score_counts.index\n",
        "    score_values = score_counts.values\n",
        "\n",
        "    # Define custom colors for the pie chart\n",
        "    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0']\n",
        "\n",
        "    # Create a pie chart with count as data and unique value as labels\n",
        "    plt.pie(score_values, labels=score_labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "\n",
        "    # Add a white circle to the center of the pie chart\n",
        "    center_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
        "    fig = plt.gcf()\n",
        "    fig.gca().add_artist(center_circle)\n",
        "\n",
        "    # Set font size and title of the chart\n",
        "    plt.rcParams['font.size'] = 12\n",
        "    plt.title('Distribution of Ratings')\n",
        "\n",
        "    # Show the chart\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "    return score_counts\n"
      ],
      "metadata": {
        "id": "EtecqI3M8bB9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_new_columns():\n",
        "    data = pre_processing()\n",
        "\n",
        "    # Initialize SentimentIntensityAnalyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Apply sentiment analysis and add new columns\n",
        "    data['Positive'] = data['Text'].apply(lambda x: sia.polarity_scores(x)['pos'])\n",
        "    data['Negative'] = data['Text'].apply(lambda x: sia.polarity_scores(x)['neg'])\n",
        "    data['Neutral'] = data['Text'].apply(lambda x: sia.polarity_scores(x)['neu'])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "tcxCL7-o-1lF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_score():\n",
        "    data = add_new_columns()\n",
        "\n",
        "    # Calculate the sum of positive, negative, and neutral columns\n",
        "    positive_sum = data['Positive'].sum()\n",
        "    negative_sum = data['Negative'].sum()\n",
        "    neutral_sum = data['Neutral'].sum()\n",
        "\n",
        "    # Find the maximum sentiment\n",
        "    if positive_sum > negative_sum and positive_sum > neutral_sum:\n",
        "        return \"Positive\"\n",
        "    elif negative_sum > positive_sum and negative_sum > neutral_sum:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MHZEmThX_Xdu"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}